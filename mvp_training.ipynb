{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA MVP Prediction\n",
    "### Regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mvp_votings.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation\n",
    "\n",
    "Cross-validation by using all seasons for training, except one season, used for validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures, normalize, StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor, AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import shuffle\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(data_frame, estimators, params, filename, poly_fit=None, scaler=None):\n",
    "    seasons = data_frame.season.unique()\n",
    "    features = ['ts_pct', 'bpm', 'usg_pct', 'pts_per_g', 'trb_per_g', 'per', 'ws_per_48', 'win_pct']\n",
    "    target = ['award_share']\n",
    "    \n",
    "    for handler in logging.root.handlers[:]:\n",
    "        logging.root.removeHandler(handler)\n",
    "    logging.basicConfig(filename=filename, filemode='w', level=logging.INFO)\n",
    "    logger = logging.getLogger()\n",
    "    \n",
    "    minimal_error, best_estimator = None, None\n",
    "    \n",
    "    for estimator in estimators:\n",
    "        print(f\"Starting with estimator: {estimator.__name__}\")\n",
    "        logging.info(f\"Starting with estimator: {estimator.__name__}\")\n",
    "            \n",
    "        for index, curr_params in enumerate(params[estimator.__name__]):\n",
    "            regressor = estimator(**curr_params)\n",
    "            errors = [] # MSE for each split\n",
    "            accuracies = [] # accuracies for each split\n",
    "            best_accuracies = []\n",
    "                \n",
    "            for season in seasons:\n",
    "                train_data = data_frame.loc[data_frame.season != season]\n",
    "                validation_data = data_frame.loc[data_frame.season == season]\n",
    "                validation_data = validation_data.sort_values(by='award_share', ascending=False)\n",
    "                    \n",
    "                # Get train data\n",
    "                train_x = train_data[features].to_numpy()\n",
    "                train_y = train_data[target].to_numpy()\n",
    "                train_y = train_y.reshape(train_y.shape[0], )\n",
    "                    \n",
    "                # Validate over one season only\n",
    "                val_x = validation_data[features].to_numpy()\n",
    "                val_y = validation_data[target].to_numpy()\n",
    "                val_y = val_y.reshape(val_y.shape[0], )\n",
    "                \n",
    "                if poly_fit:\n",
    "                    train_x = poly_fit.fit_transform(train_x)\n",
    "                    val_x = poly_fit.fit_transform(val_x)\n",
    "                        \n",
    "                if scaler:\n",
    "                    train_x = scaler.fit_transform(train_x)\n",
    "                    val_x = scaler.fit_transform(val_x)\n",
    "                        \n",
    "                shuffle_x, shuffle_y = shuffle(train_x, train_y)\n",
    "                    \n",
    "                regressor.fit(shuffle_x, shuffle_y)\n",
    "                predicted_y = regressor.predict(val_x)\n",
    "                    \n",
    "                sorted_indices = np.argsort(predicted_y)[::-1]\n",
    "                correct_indices = np.arange(len(val_y))\n",
    "                    \n",
    "                accuracy = np.sum(sorted_indices[:5] == correct_indices[:5] / len(correct_indices[:5]))\n",
    "                accuracies.append(accuracy)\n",
    "                    \n",
    "                best_accuracies.append(np.sum(sorted_indices[:1] == correct_indices[:5]) / len(correct_indices[:1]))\n",
    "                    \n",
    "                curr_error = mean_squared_error(val_y, predicted_y)\n",
    "                errors.append(curr_error)\n",
    "                \n",
    "            mean_error = np.average(errors)\n",
    "            mean_accuracy = np.average(accuracies)\n",
    "            mean_acc_at_1 = np.average(best_accuracies)\n",
    "            logging.info(f\"Parameters: {curr_params}, \" \\\n",
    "                         f\"MSE over all splits is: {mean_error:.4f}, \" \\\n",
    "                         f\"Mean accuracy at 5: {mean_accuracy:.4f}, \" \\\n",
    "                         f\"Mean accuracy at 1: {mean_acc_at_1:.4f} \"\n",
    "                        )\n",
    "            print(f\"Parameters: {curr_params}, \" \\\n",
    "                  f\"MSE over all splits is: {mean_error:.4f}, \" \\\n",
    "                  f\"Mean accuracy at 5: {mean_accuracy:.4f}, \" \\\n",
    "                  f\"Mean accuracy at 1: {mean_acc_at_1:.4f} \")\n",
    "            \n",
    "            if minimal_error is None or mean_error < minimal_error:\n",
    "                minimal_error = mean_error\n",
    "                best_estimator = estimator(*curr_params)\n",
    "        \n",
    "    return best_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining estimators and their parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [LinearRegression]\n",
    "params = {\n",
    "    LinearRegression.__name__: [\n",
    "        {\n",
    "            'n_jobs': -1,\n",
    "        },\n",
    "        {\n",
    "            'n_jobs': -1,\n",
    "            'normalize': True\n",
    "        },\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run pipeline to find best estimator to predict the NBA MVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with estimator: LinearRegression\n",
      "Parameters: {'n_jobs': -1}, MSE over all splits is: 0.0361, Mean accuracy at 5: 0.6579, Mean accuracy at 1: 1.0000 \n",
      "Parameters: {'n_jobs': -1, 'normalize': True}, MSE over all splits is: 0.0397, Mean accuracy at 5: 0.6053, Mean accuracy at 1: 0.9474 \n"
     ]
    }
   ],
   "source": [
    "best_estimator = pipeline(\n",
    "    data_frame=df,\n",
    "    estimators=estimators,\n",
    "    params=params,\n",
    "    filename=\"temp.txt\",\n",
    "    poly_fit=PolynomialFeatures(degree=2, interaction_only=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the MVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_data.csv')\n",
    "top_players = pd.read_csv('top_players.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['ts_pct', 'bpm', 'mp_per_g', 'pts_per_g', 'trb_per_g', 'ast_per_g',\n",
    "            'stl_per_g', 'blk_per_g', 'ws', 'win_pct']\n",
    "target = ['award_share']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_for_regression_model(model, poly_fit, train_data, val_data, scaler=None, should_print=True):\n",
    "    train_x = train_data[features]\n",
    "    train_y = train_data[target]\n",
    "    \n",
    "    train_x, train_y = shuffle(train_x, train_y)\n",
    "    \n",
    "    test_x = test_data[features].to_numpy()\n",
    "    test_x = np.nan_to_num(test_x)\n",
    "    \n",
    "    if poly_fit:\n",
    "        train_x = poly_fit.fit_transform(train_x)\n",
    "        test_x = poly_fit.fit_transform(test_x)\n",
    "        \n",
    "    if scaler:\n",
    "        train_x = scaler.fit_transform(train_x)\n",
    "        test_x = scaler.fit_transform(test_x)\n",
    "        \n",
    "    model.fit(train_x, train_y.values.ravel())\n",
    "    predict_y = model.predict(test_x)\n",
    "    sorted_indices = np.argsort(predict_y)[::-1]\n",
    "    predictions = predict_y[sorted_indices]\n",
    "    \n",
    "    formatted_preds = []\n",
    "    if should_print:\n",
    "        print(f\"Predictions\")\n",
    "    for i in range(10):\n",
    "        if predictions[i] < 0:\n",
    "            break\n",
    "        if should_print:\n",
    "            print(f\"{i+1}. {top_players.iloc[sorted_indices[i]].Player}: {predictions[i]}\")\n",
    "        formatted_preds.append((top_players.iloc[sorted_indices[i]].Player, predictions[i]))\n",
    "    return formatted_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions\n",
      "1. James Harden: 0.7376242046085356\n",
      "2. Giannis Antetokounmpo: 0.725515666993111\n",
      "3. Joel Embiid: 0.29815014201398854\n",
      "4. Kawhi Leonard: 0.26369955851669674\n",
      "5. Paul George: 0.17653668514623136\n",
      "6. Stephen Curry: 0.1740185306574057\n",
      "7. Nikola Jokic: 0.1725925733183824\n",
      "8. Rudy Gobert: 0.1546860022795456\n",
      "9. Russell Westbrook: 0.1306408948130648\n",
      "10. Damian Lillard: 0.10123934904712832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('James Harden', 0.7376242046085356),\n",
       " ('Giannis Antetokounmpo', 0.725515666993111),\n",
       " ('Joel Embiid', 0.29815014201398854),\n",
       " ('Kawhi Leonard', 0.26369955851669674),\n",
       " ('Paul George', 0.17653668514623136),\n",
       " ('Stephen Curry', 0.1740185306574057),\n",
       " ('Nikola Jokic', 0.1725925733183824),\n",
       " ('Rudy Gobert', 0.1546860022795456),\n",
       " ('Russell Westbrook', 0.1306408948130648),\n",
       " ('Damian Lillard', 0.10123934904712832)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions_for_regression_model(\n",
    "    model=GradientBoostingRegressor(n_estimators=50, learning_rate=0.1, subsample=1.0),\n",
    "    poly_fit=PolynomialFeatures(degree=2, interaction_only=False),\n",
    "    train_data=df,\n",
    "    val_data=test_data\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
